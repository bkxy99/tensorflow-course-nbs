{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[15 25]\n",
      " [35 45]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[100 200]\n",
      " [300 400]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 5 15]\n",
      " [25 35]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ts = tf.constant([\n",
    "    [10, 20],\n",
    "    [30, 40]\n",
    "])\n",
    "\n",
    "print(ts + 5)\n",
    "print(ts * 10)\n",
    "print(ts - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100, 200],\n",
       "       [300, 400]], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ts = tf.multiply(ts, 10) # performance benefits for using tf.add/subtract etc. over +/- etc.\n",
    "\n",
    "new_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[114, 228,   6],\n",
       "       [240, 480,  15]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = tf.constant([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "\n",
    "m2 = tf.constant([\n",
    "    [2,4,1],\n",
    "    [8,16,1],\n",
    "    [32,64,1]\n",
    "])\n",
    "\n",
    "tf.matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[114, 228,   6],\n",
       "       [240, 480,  15]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 @ m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2) (3, 2)\n",
      "New shape of Y is: [[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "tf.Tensor(\n",
      "[[ 39  54  69]\n",
      " [ 49  68  87]\n",
      " [ 59  82 105]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([\n",
    "    [7, 8],\n",
    "    [9, 10],\n",
    "    [11, 12]\n",
    "])\n",
    "\n",
    "Y = tf.constant([\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# print(tf.matmul(X, Y)) # matrix size incompatible error\n",
    "\n",
    "# 2 * 3 OR 3 * 2 = 6 reshaping can be done as long as the new shape has equal elements as before\n",
    "Y = tf.reshape(Y, shape=(2, 3))\n",
    "\n",
    "print(f\"New shape of Y is: {Y}\\n\")\n",
    "\n",
    "print(tf.matmul(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing Tensors\n",
    "\n",
    "Matrix transpose operation flips the axes of the elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  9, 11],\n",
       "       [ 8, 10, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant([\n",
    "    [7, 8],\n",
    "    [9, 10],\n",
    "    [11, 12]\n",
    "])\n",
    "\n",
    "tf.transpose(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot product\n",
    "\n",
    "these can be used:\n",
    "- `tf.matmul()`\n",
    "- `tf.tensordot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       " array([[ 39,  54,  69],\n",
       "        [ 49,  68,  87],\n",
       "        [ 59,  82, 105]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       " array([[ 39,  54,  69],\n",
       "        [ 49,  68,  87],\n",
       "        [ 59,  82, 105]], dtype=int32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, Y), tf.tensordot(X, Y, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Type Casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 7.,  8.],\n",
       "       [ 9., 10.],\n",
       "       [11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant([\n",
    "    [7, 8],\n",
    "    [9, 10],\n",
    "    [11, 12]\n",
    "])\n",
    "\n",
    "X_f32 = tf.cast(X, dtype=tf.float32)\n",
    "\n",
    "X_f32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor tf.Tensor(\n",
      "[  3  -3 -74  98 -74 -19  71  27  42   7  31  86 -80 -47  15 -38  28  53\n",
      " -74  47  63  69 -62  29 -86   9 -34 -43 -75  14 -76  83  60   8 -75 -44\n",
      "  35 -39 -20 -55 -76  76 -92 -50  81  12 -76  88 -71  -8], shape=(50,), dtype=int32) \n",
      "\n",
      "Absolute tf.Tensor(\n",
      "[ 3  3 74 98 74 19 71 27 42  7 31 86 80 47 15 38 28 53 74 47 63 69 62 29\n",
      " 86  9 34 43 75 14 76 83 60  8 75 44 35 39 20 55 76 76 92 50 81 12 76 88\n",
      " 71  8], shape=(50,), dtype=int32) \n",
      "\n",
      "Min -92\n",
      "Max 98\n",
      "Mean -5\n",
      "Variance 3294.9055\n",
      "Std 57.401268\n",
      "the max value 98 lies at index 3\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.Generator.from_seed(42).uniform((50,), -100, 100, dtype=tf.int32)\n",
    "print(\"Tensor\", X, \"\\n\")\n",
    "\n",
    "# Absolute value\n",
    "print(\"Absolute\", tf.abs(X), \"\\n\")\n",
    "\n",
    "# Min\n",
    "print(\"Min\", tf.reduce_min(X).numpy())\n",
    "\n",
    "# Max\n",
    "print(\"Max\", tf.reduce_max(X).numpy())\n",
    "\n",
    "# Mean\n",
    "print(\"Mean\", tf.reduce_mean(X).numpy())\n",
    "\n",
    "# Variance\n",
    "print(\"Variance\", tf.math.reduce_variance(tf.cast(X, tf.float32)).numpy())\n",
    "\n",
    "# Standard Deviation\n",
    "print(\"Std\", tf.math.reduce_std(tf.cast(X, tf.float32)).numpy())\n",
    "\n",
    "# positional max\n",
    "print(f\"the max value {tf.reduce_max(X).numpy()} lies at index {tf.argmax(X).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeezing Tensors\n",
    "\n",
    "`tf.squeeze(tensor)` removes all the single dimensions and returns a tensor with all the dimensions of length 1 removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       "array([[[[[0.7493447 , 0.73561966, 0.45230794, 0.49039817, 0.1889317 ,\n",
       "           0.52027524, 0.8736881 , 0.46921718, 0.63932586, 0.6467117 ,\n",
       "           0.96246755, 0.41009164, 0.86540747, 0.8862978 , 0.27795732,\n",
       "           0.8857763 , 0.2179842 , 0.29115117, 0.03953862, 0.8136791 ,\n",
       "           0.8139852 , 0.52180684, 0.12496924, 0.5488483 , 0.7755773 ,\n",
       "           0.6184403 , 0.24936223, 0.89341843, 0.28422844, 0.70332646,\n",
       "           0.2622137 , 0.4432162 , 0.466465  , 0.05981874, 0.40098202,\n",
       "           0.69292355, 0.1284684 , 0.22770369, 0.33691216, 0.5329138 ,\n",
       "           0.5914326 , 0.21738243, 0.5322075 , 0.05148339, 0.03951418,\n",
       "           0.41866875, 0.78939915, 0.04384279, 0.96955836, 0.49116182]]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.Generator.from_seed(42).uniform((50,))\n",
    "X = tf.constant(X, shape=(1,1,1,1,50))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un-squeezed tf.Tensor(\n",
      "[[[[[[0.7493447  0.73561966]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.45230794 0.49039817]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.1889317  0.52027524]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.8736881  0.46921718]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.63932586 0.6467117 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.96246755 0.41009164]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.86540747 0.8862978 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.27795732 0.8857763 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.2179842  0.29115117]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.03953862 0.8136791 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.8139852  0.52180684]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.12496924 0.5488483 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.7755773  0.6184403 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.24936223 0.89341843]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.28422844 0.70332646]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.2622137  0.4432162 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.466465   0.05981874]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.40098202 0.69292355]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.1284684  0.22770369]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.33691216 0.5329138 ]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.5914326  0.21738243]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.5322075  0.05148339]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.03951418 0.41866875]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.78939915 0.04384279]]]]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[[[[0.96955836 0.49116182]]]]]], shape=(25, 1, 1, 1, 1, 2), dtype=float32)\n",
      "squeezed tf.Tensor(\n",
      "[[0.7493447  0.73561966]\n",
      " [0.45230794 0.49039817]\n",
      " [0.1889317  0.52027524]\n",
      " [0.8736881  0.46921718]\n",
      " [0.63932586 0.6467117 ]\n",
      " [0.96246755 0.41009164]\n",
      " [0.86540747 0.8862978 ]\n",
      " [0.27795732 0.8857763 ]\n",
      " [0.2179842  0.29115117]\n",
      " [0.03953862 0.8136791 ]\n",
      " [0.8139852  0.52180684]\n",
      " [0.12496924 0.5488483 ]\n",
      " [0.7755773  0.6184403 ]\n",
      " [0.24936223 0.89341843]\n",
      " [0.28422844 0.70332646]\n",
      " [0.2622137  0.4432162 ]\n",
      " [0.466465   0.05981874]\n",
      " [0.40098202 0.69292355]\n",
      " [0.1284684  0.22770369]\n",
      " [0.33691216 0.5329138 ]\n",
      " [0.5914326  0.21738243]\n",
      " [0.5322075  0.05148339]\n",
      " [0.03951418 0.41866875]\n",
      " [0.78939915 0.04384279]\n",
      " [0.96955836 0.49116182]], shape=(25, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.reshape(X, (25,1,1,1,1,2))\n",
    "\n",
    "print(\"Un-squeezed\", X)\n",
    "\n",
    "X_squeezed = tf.squeeze(X)\n",
    "\n",
    "print(\"squeezed\", X_squeezed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPUs\n",
    "\n",
    "Google colab provides access to different runtimes including CUDA enabled GPUs & Google's own TPUs for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
